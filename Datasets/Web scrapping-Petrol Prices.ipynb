{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd38bac",
   "metadata": {},
   "source": [
    "pip install tabula-py pandas requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f90e08c",
   "metadata": {},
   "source": [
    "pip install pdfplumber\n",
    "pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37edf210",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shashanksingh/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/shashanksingh/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "#Importing the Libraries \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "import pdfplumber\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 - Helper Function (Define a function to clean up).\n",
    "def clean_price(price_str):\n",
    "    if isinstance(price_str, str):\n",
    "        cleaned_str = price_str.replace(\" \",\"\")\n",
    "        try:\n",
    "            return float(cleaned_str)\n",
    "        except ValueError:\n",
    "            return pd.Na\n",
    "    return price_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a3d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 - Url \n",
    "base_url = 'https://www.ppac.gov.in/'\n",
    "page_url = \"https://ppac.gov.in/retail-selling-price-rsp-of-petrol-diesel-and-domestic-lpg/rsp-of-petrol-and-diesel-in-metro-cities-since-16-6-2017\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa932c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found PDF at: https://ppac.gov.in/uploads/page-images/1761110504_PP_9_a_DailyPriceMSHSD_Metro_22.10.2025.pdf\n",
      "Attempting to read tables from ALL pages...\n",
      "Successfully extracted header: ['', 'Date of\\nRevision', 'Delhi', 'Mumbai', 'Chennai', 'Kolkata', '', 'Date of Revision', 'Delhi', 'Mumbai', 'Chennai', 'Kolkata', '']\n",
      "Processing page 1 of 35...\n",
      "  - Added 97 data rows.\n",
      "Processing page 2 of 35...\n",
      "  - Added 91 data rows.\n",
      "Processing page 3 of 35...\n",
      "  - Added 91 data rows.\n",
      "Processing page 4 of 35...\n",
      "  - Added 91 data rows.\n",
      "Processing page 5 of 35...\n",
      "  - Added 91 data rows.\n",
      "Processing page 6 of 35...\n",
      "  - Added 91 data rows.\n",
      "Processing page 7 of 35...\n",
      "  - Added 91 data rows.\n",
      "Processing page 8 of 35...\n",
      "  - Added 91 data rows.\n",
      "Processing page 9 of 35...\n",
      "  - Added 91 data rows.\n",
      "Processing page 10 of 35...\n",
      "  - Added 91 data rows.\n",
      "Processing page 11 of 35...\n",
      "  - Added 91 data rows.\n",
      "Processing page 12 of 35...\n",
      "  - Added 91 data rows.\n",
      "Processing page 13 of 35...\n",
      "  - Added 89 data rows.\n",
      "Processing page 14 of 35...\n",
      "  - Added 88 data rows.\n",
      "Processing page 15 of 35...\n",
      "  - Added 88 data rows.\n",
      "Processing page 16 of 35...\n",
      "  - Added 88 data rows.\n",
      "Processing page 17 of 35...\n",
      "  - Added 88 data rows.\n",
      "Processing page 18 of 35...\n",
      "  - Added 88 data rows.\n",
      "Processing page 19 of 35...\n",
      "  - Added 88 data rows.\n",
      "Processing page 20 of 35...\n",
      "  - Added 88 data rows.\n",
      "Processing page 21 of 35...\n",
      "  - Added 88 data rows.\n",
      "Processing page 22 of 35...\n",
      "  - Added 88 data rows.\n",
      "Processing page 23 of 35...\n",
      "  - Added 88 data rows.\n",
      "Processing page 24 of 35...\n",
      "  - Added 88 data rows.\n",
      "Processing page 25 of 35...\n",
      "  - Added 88 data rows.\n",
      "Processing page 26 of 35...\n",
      "  - Added 85 data rows.\n",
      "Processing page 27 of 35...\n",
      "  - Added 80 data rows.\n",
      "Processing page 28 of 35...\n",
      "  - Added 80 data rows.\n",
      "Processing page 29 of 35...\n",
      "  - Added 80 data rows.\n",
      "Processing page 30 of 35...\n",
      "  - Added 80 data rows.\n",
      "Processing page 31 of 35...\n",
      "  - Added 80 data rows.\n",
      "Processing page 32 of 35...\n",
      "  - Added 80 data rows.\n",
      "Processing page 33 of 35...\n",
      "  - Added 80 data rows.\n",
      "Processing page 34 of 35...\n",
      "  - Added 80 data rows.\n",
      "Processing page 35 of 35...\n",
      "  - Added 49 data rows.\n",
      "\n",
      "Total data rows found across all pages: 3017\n"
     ]
    }
   ],
   "source": [
    "#Step 3 - Scraping and Parsing\n",
    "try:\n",
    "    response = requests.get(page_url) #download the content.\n",
    "    response.raise_for_status() #check for successful download no 404 errors.\n",
    "    soup = BeautifulSoup(response.text, 'html.parser') #parse the content.\n",
    "    pdf_link_tag = soup.find('a', href=lambda href: href and 'DailyPriceMSHSD_Metro' in href)\n",
    "    \n",
    "    if not pdf_link_tag:\n",
    "        print(\"Error: Could not find the PDF link on the page.\")\n",
    "        exit()\n",
    "\n",
    "    pdf_relative_url = pdf_link_tag['href']\n",
    "    pdf_full_url = urljoin(f\"https://{base_url}\", pdf_relative_url)\n",
    "    print(f\"Found PDF at: {pdf_full_url}\")\n",
    "\n",
    "    pdf_response = requests.get(pdf_full_url)\n",
    "    pdf_response.raise_for_status()\n",
    "    print(\"Attempting to read tables from ALL pages...\")\n",
    "    \n",
    "    all_data_rows = [] #A list to store all data rows from all pages.\n",
    "    header = None  #A variable to store the column headers.\n",
    "\n",
    "    with pdfplumber.open(io.BytesIO(pdf_response.content)) as pdf:\n",
    "        try:\n",
    "            first_page_tables = pdf.pages[0].extract_tables()\n",
    "            header = first_page_tables[0][3]\n",
    "            print(f\"Successfully extracted header: {header}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fatal Error: Could not extract header from page 1. {e}\") #If the header can't be found, the script can't continue.\n",
    "            exit()\n",
    "        for i, page in enumerate(pdf.pages): #Loop\n",
    "            print(f\"Processing page {i+1} of {len(pdf.pages)}...\")\n",
    "            tables = page.extract_tables()\n",
    "            \n",
    "            if not tables or len(tables) < 1:\n",
    "                print(f\"  - No tables found on page {i+1}.\")\n",
    "                continue\n",
    "                \n",
    "            combined_table_data = tables[0]\n",
    "            data_on_this_page = combined_table_data[6:] \n",
    "\n",
    "            \n",
    "            all_data_rows.extend(data_on_this_page) \n",
    "            print(f\"  - Added {len(data_on_this_page)} data rows.\")\n",
    "\n",
    "    print(f\"\\nTotal data rows found across all pages: {len(all_data_rows)}\")\n",
    "\n",
    "    if not all_data_rows:\n",
    "        print(\"Error: No data rows were found in the entire PDF.\")\n",
    "        exit()\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error fetching the URL: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4 - Data Restructuring and Cleaning\n",
    "#Splitting the dataframe \n",
    "full_df = pd.DataFrame(all_data_rows, columns=header)\n",
    "petrol_df = full_df.iloc[:, 1:6] \n",
    "diesel_df = full_df.iloc[:, 7:12]\n",
    "\n",
    "clean_columns = ['Date', 'Delhi', 'Mumbai', 'Chennai', 'Kolkata']\n",
    "petrol_df.columns = clean_columns\n",
    "diesel_df.columns = clean_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a646c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping the dataframe \n",
    "petrol_long = pd.melt(petrol_df, \n",
    "                          id_vars=['Date'], \n",
    "                          value_vars=['Delhi', 'Mumbai', 'Chennai', 'Kolkata'],\n",
    "                          var_name='City', \n",
    "                          value_name='Petrol_Price')\n",
    "    \n",
    "diesel_long = pd.melt(diesel_df, \n",
    "                          id_vars=['Date'], \n",
    "                          value_vars=['Delhi', 'Mumbai', 'Chennai', 'Kolkata'],\n",
    "                          var_name='City', \n",
    "                          value_name='Diesel_Price')\n",
    "    \n",
    "final_df = pd.merge(petrol_long, diesel_long, on=['Date', 'City']) #Merging the Dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b9433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5 - Data Type Conversion.\n",
    "final_df['Date'] = final_df['Date'].str.split('\\n').str[0].str.strip()\n",
    "final_df['Date'] = pd.to_datetime(final_df['Date'], format='%d-%b-%y')\n",
    "final_df['Petrol_Price'] = final_df['Petrol_Price'].apply(clean_price)\n",
    "final_df['Diesel_Price'] = final_df['Diesel_Price'].apply(clean_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c633c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.dropna(subset=['Petrol_Price', 'Diesel_Price'], how='all', inplace=True)\n",
    "final_df.sort_values(by=['Date', 'City'], ascending=[False, True], inplace=True)\n",
    "final_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1a64252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12068 entries, 0 to 12067\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Date          12068 non-null  datetime64[ns]\n",
      " 1   City          12068 non-null  object        \n",
      " 2   Petrol_Price  12068 non-null  float64       \n",
      " 3   Diesel_Price  12068 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), object(1)\n",
      "memory usage: 377.2+ KB\n",
      "\n",
      "DataFrame Head (First 5 Rows):\n",
      "        Date     City  Petrol_Price  Diesel_Price\n",
      "0 2025-10-22  Chennai        100.80         92.39\n",
      "1 2025-10-22    Delhi         94.77         87.67\n",
      "2 2025-10-22  Kolkata        105.41         92.02\n",
      "3 2025-10-22   Mumbai        103.50         90.03\n",
      "4 2025-10-21  Chennai        100.80         92.39\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDataFrame Info:\")\n",
    "final_df.info()\n",
    "    \n",
    "print(\"\\nDataFrame Head (First 5 Rows):\")\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56ceb2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>City</th>\n",
       "      <th>Petrol_Price</th>\n",
       "      <th>Diesel_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12063</th>\n",
       "      <td>2017-06-17</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>76.46</td>\n",
       "      <td>59.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12064</th>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>68.02</td>\n",
       "      <td>57.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12065</th>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>65.48</td>\n",
       "      <td>54.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12066</th>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>68.03</td>\n",
       "      <td>56.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12067</th>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>76.70</td>\n",
       "      <td>59.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date     City  Petrol_Price  Diesel_Price\n",
       "12063 2017-06-17   Mumbai         76.46         59.73\n",
       "12064 2017-06-16  Chennai         68.02         57.41\n",
       "12065 2017-06-16    Delhi         65.48         54.49\n",
       "12066 2017-06-16  Kolkata         68.03         56.65\n",
       "12067 2017-06-16   Mumbai         76.70         59.90"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0082d39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved all data to 'fuel_prics.csv'\n"
     ]
    }
   ],
   "source": [
    "final_df.to_csv('fuel_prices.csv', index=False)\n",
    "print(\"\\nSuccessfully saved all data to 'fuel_prics.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
